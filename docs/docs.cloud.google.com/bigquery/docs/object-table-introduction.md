# Introduction to object tables

**Important:** The term "BigLake" on this page refers to an access delegation functionality for external tables in BigQuery. For information about BigLake, the stand-alone Google Cloud product that includes BigLake metastore, the Apache Iceberg REST catalog, and BigLake tables for Apache Iceberg see [BigLake overview](/biglake/docs/introduction) .

This document describes object tables, which are read-only tables over unstructured data objects that reside in Cloud Storage.

Object tables let you analyze unstructured data in Cloud Storage. You can perform analysis with remote functions or perform inference by using BigQuery ML, and then join the results of these operations with the rest of your structured data in BigQuery.

Like BigLake tables, object tables use access delegation, which decouples access to the object table from access to the Cloud Storage objects. An [external connection](/bigquery/docs/working-with-connections) associated with a service account is used to connect to Cloud Storage, so you only have to grant users access to the object table. This lets you enforce [row-level](/bigquery/docs/row-level-security-intro) security and manage which objects users have access to.

You can use the [`  CREATE EXTERNAL TABLE  ` statement](/bigquery/docs/reference/standard-sql/data-definition-language#create_external_table_statement) to create an object table, as shown in the following example:

``` text
CREATE EXTERNAL TABLE `myproject.mydataset.myobjecttable`
WITH CONNECTION `myproject.us.myconnection`
OPTIONS ( object_metadata = 'SIMPLE', uris = ['gs://mybucket/*'] );
```

To learn more about creating object tables, see [Create object tables](/bigquery/docs/object-tables) .

**Note:** When managing access for users in [external identity providers](/iam/docs/workforce-identity-federation) , replace instances of Google Account principal identifiers—like `  user:kiran@example.com  ` , `  group:support@example.com  ` , and `  domain:example.com  ` —with appropriate [Workforce Identity Federation principal identifiers](/iam/docs/principal-identifiers) .

## Object table schema

An object table provides a metadata index over the unstructured data objects in a specified Cloud Storage bucket. Each row of the table corresponds to an object, and the table columns correspond to the object metadata generated by Cloud Storage, including any [custom metadata](/storage/docs/metadata#custom-metadata) .

An object table also contains a `  data  ` pseudocolumn that represents the file content in raw bytes, which is auto-populated when the object table is created. This pseudocolumn is used by the [`  ML.DECODE_IMAGE  ` function](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-decode-image) when you run inference on image data. You can't include the `  data  ` pseudocolumn in queries, and it doesn't appear as part of the object table schema.

The following table describes the fixed schema used by object tables:

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Field name</strong></th>
<th><strong>Type</strong></th>
<th><strong>Mode</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code dir="ltr" translate="no">       uri      </code></td>
<td>STRING</td>
<td>NULLABLE</td>
<td><code dir="ltr" translate="no">       uri      </code> : the Uniform Resource Identifier (URI) of the object, in the format <code dir="ltr" translate="no">       gs://bucket_name/[folder_name/]object_name      </code> .</td>
</tr>
<tr class="even">
<td><code dir="ltr" translate="no">       generation      </code></td>
<td>INTEGER</td>
<td>NULLABLE</td>
<td>The <a href="/storage/docs/metadata#generation-number">generation</a> of this object, which identifies the object version.</td>
</tr>
<tr class="odd">
<td><code dir="ltr" translate="no">       content_type      </code></td>
<td>STRING</td>
<td>NULLABLE</td>
<td>The <a href="/storage/docs/metadata#content-type">Content-Type</a> of the object data, which identifies what kind of media it is. If an object is stored without a Content-Type, it is served as application/octet-stream.</td>
</tr>
<tr class="even">
<td><code dir="ltr" translate="no">       size      </code></td>
<td>INTEGER</td>
<td>NULLABLE</td>
<td>The <a href="https://datatracker.ietf.org/doc/html/rfc7230#section-3.3.2">Content-Length</a> of the data in bytes.</td>
</tr>
<tr class="odd">
<td><code dir="ltr" translate="no">       md5_hash      </code></td>
<td>STRING</td>
<td>NULLABLE</td>
<td>The <a href="https://wikipedia.org/wiki/MD5">MD5 hash</a> of the data, encoded using <a href="https://datatracker.ietf.org/doc/html/rfc4648#section-4">base64</a> . For more information about using the MD5 hash, see <a href="/storage/docs/metadata#md5">Cloud Storage object metadata</a> .</td>
</tr>
<tr class="even">
<td><code dir="ltr" translate="no">       updated      </code></td>
<td>TIMESTAMP</td>
<td>NULLABLE</td>
<td>The last time the object's metadata was modified.</td>
</tr>
<tr class="odd">
<td><code dir="ltr" translate="no">       metadata      </code></td>
<td>RECORD</td>
<td>REPEATED</td>
<td><a href="/storage/docs/metadata#custom-metadata">Custom metadata</a> for the object. Each piece of metadata is represented as a key-value pair in the child <code dir="ltr" translate="no">       (metadata.)name      </code> and <code dir="ltr" translate="no">       (metadata.)value      </code> fields of the <code dir="ltr" translate="no">       metadata      </code> field.</td>
</tr>
<tr class="even">
<td><code dir="ltr" translate="no">       (metadata.)name      </code></td>
<td>STRING</td>
<td>NULLABLE</td>
<td>Key in an individual metadata entry.</td>
</tr>
<tr class="odd">
<td><code dir="ltr" translate="no">       (metadata.)value      </code></td>
<td>STRING</td>
<td>NULLABLE</td>
<td>Value in an individual metadata entry.</td>
</tr>
<tr class="even">
<td><code dir="ltr" translate="no">       ref      </code></td>
<td>STRUCT</td>
<td>NULLABLE</td>
<td>Google-managed Cloud Storage metadata stored in the <a href="/bigquery/docs/reference/standard-sql/objectref_functions#objectref"><code dir="ltr" translate="no">        ObjectRef       </code> format</a> .<br />
( <a href="https://cloud.google.com/products#product-launch-stages">Preview</a> )<br />
<br />
You can use this column <a href="/bigquery/docs/objectref-columns">to maintain <code dir="ltr" translate="no">        ObjectRef       </code> values in standard tables</a> . <code dir="ltr" translate="no">       ObjectRef      </code> values let you integrate object data with structured data. This column is created only if you are on the allowlist for the <a href="/bigquery/docs/analyze-multimodal-data">multimodal data preview</a> .</td>
</tr>
</tbody>
</table>

The rows in an object table look similar to the following:

``` text
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
|  uri                 | generation | content_type | size  | md5_hash   | updated                        | metadata...name | metadata...value  | ref.uri              | ref.version | ref.authorizer | ref.details                                              |
—----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| gs://mybucket/a.jpeg | 165842…    | image/jpeg   | 26797 | 8c33be10f… | 2022-07-21 17:35:40.148000 UTC | null            | null              | gs://mybucket/a.jpeg | 12345678    | us.conn        | {"gcs_metadata":{"content_type":"image/jpeg","md5_hash"… |
—----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| gs://mybucket/b.bmp  | 305722…    | image/bmp    | 57932 | 44eb90cd1… | 2022-05-14 12:09:38.114000 UTC | null            | null              | gs://mybucket/b.bmp  | 23456789    | us.conn        | {"gcs_metadata":{"content_type":"image/bmp","md5_hash"…  |
—----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
```

## Use cases

You can query the metadata in an object table in the same way you would query any other BigQuery table. However, the primary use case for object tables is to make unstructured data accessible for analysis. You can use BigQuery ML to [run inference on image object tables](/bigquery/docs/object-table-inference) with TensorFlow, TensorFlow Lite, and PyTorch models. You can also use [remote functions](/bigquery/docs/remote-functions) to [analyze unstructured data](/bigquery/docs/object-table-remote-function) almost any way you want to. For example, you could create a remote function that lets you analyze images by using [Cloud Vision](/vision/docs) , or one that lets you extract metadata from PDF documents by using [Apache Tika](https://tika.apache.org/) .

The following table describes the integration points you can use to do machine learning on object table data:

<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Integration</strong></th>
<th><strong>Description</strong></th>
<th><strong>Use case</strong></th>
<th><strong>Tutorial</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>The <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-generate-text"><code dir="ltr" translate="no">        AI.GENERATE_TEXT       </code> function</a></td>
<td>Generate text by using a Vertex AI, partner, or open model.</td>
<td>You want to generate text from object data.</td>
<td><a href="/bigquery/docs/generate-text">Generate text by using the <code dir="ltr" translate="no">        AI.GENERATE_TEXT       </code> function</a></td>
</tr>
<tr class="even">
<td>The <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-generate-embedding"><code dir="ltr" translate="no">        AI.GENERATE_EMBEDDING       </code> function</a></td>
<td>Generate embeddings by using a Vertex AI multimodal model.</td>
<td>You want to generate embeddings for video or image data to use in vector searches, model input, or other use cases.</td>
<td><a href="/bigquery/docs/generate-visual-content-embedding">Generate image embeddings by using the <code dir="ltr" translate="no">        AI.GENERATE_EMBEDDING       </code> function</a><br />
<br />
<a href="/bigquery/docs/generate-video-embedding">Generate video embeddings by using the <code dir="ltr" translate="no">        AI.GENERATE_EMBEDDING       </code> function</a></td>
</tr>
<tr class="odd">
<td><a href="/bigquery/docs/reference/standard-sql/inference-overview#inference_using_imported_models">Imported BigQuery ML models</a></td>
<td>Import <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tensorflow">TensorFlow</a> , <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tflite">TensorFlow Lite</a> , or <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-onnx">ONNX</a> models to BigQuery ML to run local inference in BigQuery .</td>
<td>You are using open-source or custom models that fit within <a href="/bigquery/docs/object-table-inference#limitations">supported limitations</a> .</td>
<td><a href="/bigquery/docs/inference-tutorial-mobilenet">Tutorial: Run inference on an object table by using a feature vector model</a></td>
</tr>
<tr class="even">
<td><a href="/bigquery/docs/object-table-remote-function">Cloud Run functions</a></td>
<td>Use Cloud Run functions to call services or hosted models. This is the most generic integration.</td>
<td>You are self-hosting your models on Compute Engine, Google Kubernetes Engine, or other customer-owned infrastructure.</td>
<td></td>
</tr>
<tr class="odd">
<td>The <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-annotate-image"><code dir="ltr" translate="no">        ML.ANNOTATE_IMAGE       </code> function</a></td>
<td>Use the Cloud Vision API to annotate images.</td>
<td>You want to annotate images by using a Vision API pre-trained model.</td>
<td><a href="/bigquery/docs/annotate-image">Annotate images with the <code dir="ltr" translate="no">        ML.ANNOTATE_IMAGE       </code> function</a></td>
</tr>
<tr class="even">
<td>The <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-process-document"><code dir="ltr" translate="no">        ML.PROCESS_DOCUMENT       </code> function</a></td>
<td>Use the Document AI API to extract document insights.</td>
<td>You want to use Document AI pre-trained or custom document processors.</td>
<td><a href="/bigquery/docs/process-document">Process documents with the <code dir="ltr" translate="no">        ML.PROCESS_DOCUMENT       </code> function</a></td>
</tr>
<tr class="odd">
<td>The <a href="/bigquery/docs/reference/standard-sql/bigqueryml-syntax-transcribe"><code dir="ltr" translate="no">        ML.TRANSCRIBE       </code> function</a></td>
<td>Use the Speech-to-Text API to transcribe audio files.</td>
<td>You want to use Speech-to-Text pre-trained or custom speech recognizers.</td>
<td><a href="/bigquery/docs/transcribe">Transcribe audio files with the <code dir="ltr" translate="no">        ML.TRANSCRIBE       </code> function</a></td>
</tr>
</tbody>
</table>

You can create a view or table from the results of your analysis if you want to join your results with other structured data. For example, the following statement creates a table based on inference results:

``` text
CREATE TABLE my_dataset.my_inference_results AS
SELECT uri, content_type, vision_feature
FROM ML.PREDICT(
  MODEL my_dataset.vision_model,
  SELECT ML.DECODE_IMAGE(data) AS vision_input
  FROM my_dataset.object_table
);
```

After the table is created, you can join it with other tables based on either standard or custom metadata fields, as shown following:

``` text
SELECT a.vision_feature, a.uri, b.description
FROM my_dataset.my_inference_results a
JOIN my_dataset.image_description b
ON a.uri = b.uri;
```

You can also [create a search index](/bigquery/docs/search-index) to power searches over the results of your analysis. For example, the following statement creates a search index over data extracted from PDF files:

``` text
CREATE SEARCH INDEX my_index ON pdf_text_extract(ALL COLUMNS);
```

You can then use the index to find what you need in those results:

``` text
SELECT * FROM pdf_text_extract WHERE SEARCH(pdf_text, 'Google');
```

## Benefits

Analyzing unstructured data natively in BigQuery provides the following benefits:

  - It reduces manual effort by letting you automate pre-processing steps such as tuning image sizes to model requirements.
  - It lets you use the familiar SQL interface to work with unstructured data.
  - It helps you save costs by utilizing existing BigQuery slots instead of having to provision new forms of compute.

## Signed URLs

To get access to the data represented by an object, generate a signed URL. You can use the signed URL to directly view the object data, and you can also [pass signed URLs to remote functions](/bigquery/docs/object-table-remote-function) to enable them to work with object table data.

Use the [`  EXTERNAL_OBJECT_TRANSFORM  ` function](/bigquery/docs/reference/standard-sql/table-functions-built-in#external_object_transform) to generate signed URLs, as shown in the following example:

``` text
SELECT uri, signed_url
FROM EXTERNAL_OBJECT_TRANSFORM(TABLE `mydataset.myobjecttable`, ['SIGNED_URL']);
```

This returns results similar to the following:

``` text
---------------------------------------------------------------------------------------------------
|  uri                 | signed_url                                                               |
—--------------------------------------------------------------------------------------------------
| gs://mybucket/a.docx | https://storage.googleapis.com/mybucket/a.docx?X-Goog-Signature=abcd&... |
—-------------------------------------------------------------------------------------------------
| gs://mybucket/b.pdf  | https://storage.googleapis.com/mybucket/b.pdf?X-Goog-Signature=wxyz&...  |
—--------------------------------------------------------------------------------------------------
```

Signed URLs generated from object tables allow any user or procedure that possesses them to read the corresponding objects. Generated signed URLs expire after 6 hours. For more information, see [Cloud Storage Signed URLs](/storage/docs/access-control/signed-urls) .

## Access control

Object tables are built on top of BigLake, so they use an [external connection](/bigquery/docs/working-with-connections) based on a service account to access Cloud Storage data. This decouples access to the table from access to the underlying object store through access delegation. You grant the service account permissions to access data and metadata from the objects and surface it in the table. You grant users permissions only on the table, where you can govern data access by using Identity and Access Management (IAM) and [row-level security](/bigquery/docs/row-level-security-intro) .

Object tables vary from other tables that use access delegation, in that having access to a row of an object table confers access to the underlying file content. While a user can't access the object directly, they can generate a [signed URL](#signed_urls) that lets them see the file contents. For example, if the user has access to the object table row representing the `  flower.jpg  ` image file, they can generate a signed URL to display the file and see that it is a picture of a daisy.

Setting a row-level access policy on an object table restricts a user or group's access to the object metadata in selected rows, and also to the objects represented by those rows. For example, the following statement grants the user Alice access only to rows that represent objects created before June 25, 2022:

``` text
CREATE ROW ACCESS POLICY before_20220625
ON my_dataset.my_object_table
GRANT TO ("user:alice@example.com")
FILTER USING (updated < TIMESTAMP("2022-06-25"));
```

With this row-level access policy in place, the following outcomes are true for Alice:

  - Running the query `  SELECT * FROM my_dataset.my_object_table;  ` only returns rows that have an `  updated  ` value prior to June 25, 2022.
  - Running inference on `  my_dataset.my_object_table  ` only returns predictions for objects that have an `  updated  ` value prior to June 25, 2022.
  - Generating signed URLs for `  my_dataset.my_object_table  ` only creates URLs for objects that have an `  updated  ` value prior to June 25, 2022.

You can also restrict access to object table rows by using custom metadata. For example, the following statement restricts the `  users  ` group to only access rows where the object has been tagged as not containing any personally identifiable information:

``` text
CREATE ROW ACCESS POLICY no_pii
ON my_dataset.my_object_table
GRANT TO ("group:users@example.com")
FILTER USING (ARRAY_LENGTH(metadata)=1
AND metadata[OFFSET(0)].name="no_pii")
```

## Security model

The following organizational roles are typically involved in managing and using object tables:

  - **Data lake administrators.** These administrators typically manage Identity and Access Management (IAM) policies on Cloud Storage buckets and objects.
  - **Data warehouse administrators.** These administrators typically create, delete, and update tables.
  - **Data analysts.** Analysts typically read data and run queries.

Data lake administrators are responsible for creating connections and sharing them with data warehouse administrators. In turn, data warehouse administrators create tables, set appropriate access controls, and share the tables with data analysts.

**Caution:** Data analysts should **not** have the following:

  - The ability to read objects directly from Cloud Storage (see the [Storage Object Viewer IAM role](/storage/docs/access-control/iam-roles) ), which lets data analysts circumvent access controls placed by data warehouse administrators.

  - The ability to bind tables to connections (like the BigQuery Connection Administrator).
    
    Otherwise, data analysts can create new tables that do not have any access controls, thus circumventing controls placed by data warehouse administrators.

## Supported object files

You can create an object table over any type and size of unstructured data file, and you can create remote functions to work with any type of unstructured data. However, to perform inference by using BigQuery ML, an object table can only be over image files that meet several size and type requirements. For more information, see [Limitations](/bigquery/docs/object-table-inference#limitations) .

## Metadata caching for performance

You can use cached metadata to improve the performance of inference and other types of analysis on object tables. Metadata caching is especially helpful in cases where the object table is referencing large numbers of objects. BigQuery uses CMETA as a distributed metadata system to handle large tables efficiently. CMETA provides fine-grained metadata at the column and block level, accessible through system tables. This system helps improve query performance by optimizing data access and processing. To further accelerate query performance on large tables, BigQuery maintains a metadata cache. CMETA refresh jobs keep this cache up-to-date.

The metadata includes file names, partitioning information, and physical metadata from files such as row counts. You can choose whether or not to enable metadata caching on a table. Queries with a large number of files and with Apache Hive partition filters benefit the most from metadata caching.

If you don't enable metadata caching, queries on the table must read the external data source to get object metadata. Reading this data increases the query latency; listing millions of files from the external data source can take several minutes. If you enable metadata caching, queries can avoid listing files from the external data source and can partition and prune files more quickly.

Metadata caching also integrates with Cloud Storage object versioning. When the cache is populated or refreshed, it captures metadata based on the live version of the Cloud Storage objects at that time. As a result, metadata caching-enabled queries read data corresponding to the specific cached object version, even if newer versions become live in Cloud Storage. Accessing data from any subsequently updated object versions in Cloud Storage necessitates a metadata cache refresh.

There are two properties that control this feature:

  - **Maximum staleness** specifies when queries use cached metadata.
  - **Metadata cache mode** specifies how the metadata is collected.

When you have metadata caching enabled, you specify the maximum interval of metadata staleness that is acceptable for operations against the table. For example, if you specify an interval of 1 hour, then operations against the table use cached metadata if it has been refreshed within the past hour. If the cached metadata is older than that, the operation falls back to retrieving metadata from Cloud Storage instead. You can specify a staleness interval between 30 minutes and 7 days.

When you enable metadata caching for BigLake or object tables, BigQuery triggers metadata generation refresh jobs. You can choose to refresh the cache either automatically or manually:

  - For automatic refreshes, the cache is refreshed at a system defined interval, usually somewhere between 30 and 60 minutes. Refreshing the cache automatically is a good approach if the files in Cloud Storage are added, deleted, or modified at random intervals. If you need to control the timing of the refresh, for example to trigger the refresh at the end of an extract-transform-load job, use manual refresh.

  - For manual refreshes, you run the [`  BQ.REFRESH_EXTERNAL_METADATA_CACHE  ` system procedure](/bigquery/docs/reference/system-procedures#bqrefresh_external_metadata_cache) to refresh the metadata cache on a schedule that meets your requirements. Refreshing the cache manually is a good approach if the files in Cloud Storage are added, deleted, or modified at known intervals, for example as the output of a pipeline.
    
    If you issue multiple concurrent manual refreshes, only one will succeed.

The metadata cache expires after 7 days if it isn't refreshed.

Both manual and automatic cache refreshes are executed with [`  INTERACTIVE  `](/bigquery/docs/running-queries) query priority.

### Use `     BACKGROUND    ` reservations

If you choose to use automatic refreshes, we recommend that you create a [reservation](/bigquery/docs/reservations-intro) , and then create an [assignment with a `  BACKGROUND  ` job type](/bigquery/docs/reservations-workload-management#assignments) for the project that runs the metadata cache refresh jobs. With `  BACKGROUND  ` reservations, refresh jobs use a dedicated resource pool which prevents the refresh jobs from competing with user queries, and prevents the jobs from potentially failing if there aren't sufficient resources available for them.

While using a shared slot pool incurs no extra cost, using `  BACKGROUND  ` reservations instead provides more consistent performance by allocating a dedicated resource pool, and improves the reliability of refresh jobs and overall query efficiency in BigQuery.

You should consider how the staleness interval and metadata caching mode values will interact before you set them. Consider the following examples:

  - If you are manually refreshing the metadata cache for a table, and you set the staleness interval to 2 days, you must run the `  BQ.REFRESH_EXTERNAL_METADATA_CACHE  ` system procedure every 2 days or less if you want operations against the table to use cached metadata.
  - If you are automatically refreshing the metadata cache for a table, and you set the staleness interval to 30 minutes, it is possible that some of your operations against the table might read from Cloud Storage if the metadata cache refresh takes on the longer side of the usual 30 to 60 minute window.

To find information about metadata refresh jobs, query the [`  INFORMATION_SCHEMA.JOBS  ` view](/bigquery/docs/information-schema-jobs) , as shown in the following example:

``` text
SELECT *
FROM `region-us.INFORMATION_SCHEMA.JOBS_BY_PROJECT`
WHERE job_id LIKE '%metadata_cache_refresh%'
AND creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 6 HOUR)
ORDER BY start_time DESC
LIMIT 10;
```

To learn more, see [Metadata caching](/bigquery/docs/metadata-caching) .

For more information on setting metadata caching options, see [Create object tables](/bigquery/docs/object-tables#create-object-table) .

## Limitations

  - Object tables are read-only, because they map to unstructured data objects in Cloud Storage. You can't alter an object table or modify object table data.

  - Object table support isn't available in Legacy SQL, or other cloud environments such as Amazon Web Services (AWS) and Microsoft Azure.

  - If you want to perform inference by using BigQuery ML, the model and the object table you use must meet the requirements described in [Limitations](/bigquery/docs/object-table-inference#limitations) .

  - Queries that include object tables can't access more than 10 GB of object metadata. For example, if a query accesses 100 TB from a combination of metadata columns in object tables and object data through signed URLs, only 10 GB of that 100 TB can be from the metadata columns.

  - Object tables are subject to the same limitations as all other BigQuery external tables. For more information, see [Quotas](/bigquery/quotas#external_tables) .

  - Queries over object tables are subject to the same limitations as all other BigQuery queries. For more information, see [Quotas](/bigquery/quotas#query_jobs) .

  - Remote functions that process unstructured data from object tables are subject to to the same [limitations](/bigquery/docs/remote-functions#limitations) as all other remote functions.

  - Signed URLs generated for the objects in an object tables expire after 6 hours, which is the [query execution time limit](/bigquery/quotas#query_jobs) .

  - Inference with BigQuery ML is not supported with on-demand pricing or with the Standard edition.

  - The following functions are not supported with on-demand pricing or with the Standard edition:
    
      - [`  ML.CONVERT_COLOR_SPACE  `](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-convert-color-space)
      - [`  ML.CONVERT_IMAGE_TYPE  `](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-convert-image-type)
      - [`  ML.RESIZE_IMAGE  `](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-resize-image)

  - Object tables have a maximum of 60 million rows. To take part in a [Preview](https://cloud.google.com/products#product-launch-stages) launch that increases the maximum rows to 300 million, fill out [this request form](https://forms.gle/u8cKbjWSkiytuNzy8) .

  - `  UNION ALL  ` operations that combine both empty and non-empty object tables are not supported and might return an error.

## Costs

Costs are associated with the following aspects of object tables:

  - Querying the tables.
  - [Refreshing the metadata cache](#metadata_caching_for_performance) .

If you have [slot reservations](/bigquery/docs/reservations-workload-management) , you are not charged for querying external tables. Instead, slots are consumed for these queries.

The following table shows how your pricing model affects how these costs are applied:

<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><br />
<strong>On-demand pricing</strong></th>
<th><br />
<strong>Standard, Enterprise, and Enterprise Plus editions</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><br />
Queries</td>
<td><br />
You are <a href="https://cloud.google.com/bigquery/pricing#on_demand_pricing">billed for the bytes processed</a> by user queries.</td>
<td><br />
<a href="https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing">Slots</a> in <a href="/bigquery/docs/reservations-workload-management#assignments">reservation assignments with a <code dir="ltr" translate="no">        QUERY       </code> job type</a> are consumed during query time.</td>
</tr>
<tr class="even">
<td><br />
Manually refreshing the metadata cache.</td>
<td><br />
You are <a href="https://cloud.google.com/bigquery/pricing#on_demand_pricing">billed for the bytes processed</a> to refresh the cache.</td>
<td><br />
<a href="https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing">Slots</a> in <a href="/bigquery/docs/reservations-workload-management#assignments">reservation assignments with a <code dir="ltr" translate="no">        QUERY       </code> job type</a> are consumed during cache refresh.</td>
</tr>
<tr class="odd">
<td><br />
Automatically refreshing the metadata cache.</td>
<td><br />
You are <a href="https://cloud.google.com/bigquery/pricing#on_demand_pricing">billed for the bytes processed</a> to refresh the cache.</td>
<td><br />
<a href="https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing">Slots</a> in <a href="/bigquery/docs/reservations-workload-management#assignments">reservation assignments with a <code dir="ltr" translate="no">        BACKGROUND       </code> job type</a> are consumed during cache refresh.<br />
<br />
If there are no <code dir="ltr" translate="no">       BACKGROUND      </code> reservations available for refreshing the metadata cache, BigQuery automatically uses slots in <code dir="ltr" translate="no">       QUERY      </code> reservations instead if you are using the Enterprise or Enterprise Plus edition.</td>
</tr>
</tbody>
</table>

You are also charged for storage and data access by [Cloud Storage](https://cloud.google.com/storage/pricing) , [Amazon S3](https://aws.amazon.com/s3/pricing/) , and [Azure Blob Storage](https://azure.microsoft.com/pricing/details/storage/blobs/) , subject to each product's pricing guidelines.

When BigQuery interacts with Cloud Storage, you might incur the following Cloud Storage costs:

  - Data storage costs for the amount of data stored.
  - Data retrieval costs for accessing data in [Nearline](/storage/docs/storage-classes#nearline) , [Coldline](/storage/docs/storage-classes#coldline) , and [Archive](/storage/docs/storage-classes#archive) storage classes. Take caution when querying tables or refreshing the metadata cache against these storage classes, as charges can be significant.
  - Network usage costs for data that you read across different regions, such as when your BigQuery dataset and Cloud Storage bucket are in different regions.
  - Data processing charges. However, you aren't charged for API calls that are made by BigQuery on your behalf, such as listing or getting resources.

## Using object tables with BigQuery sharing

Object tables are compatible with BigQuery sharing (formerly Analytics Hub). Datasets containing object tables can be published as [Sharing listings](/bigquery/docs/analytics-hub-introduction#listings) . Sharing subscribers can subscribe to these listings, which provision a read-only dataset, called a [*linked dataset*](/bigquery/docs/analytics-hub-introduction#linked_datasets) , in their project. Subscribers can query all tables in the linked dataset, including all object tables. For more information, see [Subscribe to a listing](/bigquery/docs/analytics-hub-view-subscribe-listings#subscribe-listings) .

## What's next

  - Learn how to [create an object table](/bigquery/docs/object-tables) .
  - Learn how to [use object tables to maintain `  ObjectRef  ` columns in standard tables](/bigquery/docs/objectref-columns) .
  - Learn how to [run inference on image object tables](/bigquery/docs/object-table-inference) .
  - Learn how to [analyze object tables by using remote functions](/bigquery/docs/object-table-remote-function) .
