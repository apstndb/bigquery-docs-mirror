# The AI.GENERATE\_BOOL function

**Preview**

This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section of the [Service Specific Terms](/terms/service-terms#1) . Pre-GA products and features are available "as is" and might have limited support. For more information, see the [launch stage descriptions](https://cloud.google.com/products/#product-launch-stages) .

**Note:** For support during the preview, contact <bqml-feedback@google.com> .

This document describes the `  AI.GENERATE_BOOL  ` function, which lets you analyze any combination of text and unstructured data. For each row in the table, the function generates a `  STRUCT  ` that contains a `  BOOL  ` value.

For example, you could use the following query to determine if titles from a table of news articles are about technology:

``` text
SELECT title, AI.GENERATE_BOOL((title, 'Is this article about technology?')).result
FROM `bigquery-public-data.bbc_news.fulltext`
LIMIT 5;
```

The function works by sending requests to a Vertex AI Gemini model, and then returning that model's response.

You can use the `  AI.GENERATE_BOOL  ` function to perform tasks such as classification and sentiment analysis.

Prompt design can strongly affect the responses returned by the model. For more information, see [Introduction to prompting](/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design) .

## Input

Using the `  AI.GENERATE_BOOL  ` function, you can use the following types of input:

  - Text data from standard tables.
  - [`  ObjectRefRuntime  `](/bigquery/docs/reference/standard-sql/objectref_functions#objectrefruntime) values that are generated by the [`  OBJ.GET_ACCESS_URL  ` function](/bigquery/docs/reference/standard-sql/objectref_functions#objget_access_url) . You can use [`  ObjectRef  `](/bigquery/docs/reference/standard-sql/objectref_functions#objectref) values from standard tables as input to the `  OBJ.GET_ACCESS_URL  ` function. ( [Preview](https://cloud.google.com/products#product-launch-stages) )

When you analyze unstructured data, that data must meet the following requirements:

  - Content must be in one of the supported formats that are described in the Gemini API model [`  mimeType  ` parameter](/vertex-ai/generative-ai/docs/model-reference/gemini#parameters) .
  - If you are analyzing a video, the maximum supported length is two minutes. If the video is longer than two minutes, `  AI.GENERATE_BOOL  ` only returns results based on the first two minutes.

## Syntax

``` text
AI.GENERATE_BOOL(
  [ prompt => ] 'PROMPT',
  [, endpoint => 'ENDPOINT']
  [, model_params => MODEL_PARAMS]
  [, connection_id => 'CONNECTION']
  [, request_type => 'REQUEST_TYPE']
)
```

### Arguments

`  AI.GENERATE_BOOL  ` takes the following arguments:

  - `  PROMPT  ` : a `  STRING  ` or `  STRUCT  ` value that specifies the `  PROMPT  ` value to send to the model. The prompt must be the first argument that you specify. You can provide the value in the following ways:
      - Specify a `  STRING  ` value. For example, 'This is a prompt.'
      - Specify a `  STRUCT  ` value that contains one or more fields. You can use the following types of fields within the `  STRUCT  ` value:
        <table>
        <colgroup>
        <col style="width: 33%" />
        <col style="width: 33%" />
        <col style="width: 33%" />
        </colgroup>
        <thead>
        <tr class="header">
        <th>Field type</th>
        <th>Description</th>
        <th>Examples</th>
        </tr>
        </thead>
        <tbody>
        <tr class="odd">
        <td><code dir="ltr" translate="no">           STRING          </code><br />
        or<br />
        <code dir="ltr" translate="no">           ARRAY&lt;STRING&gt;          </code></td>
        <td>A string literal, array of string literals, or the name of a <code dir="ltr" translate="no">           STRING          </code> column.</td>
        <td>String literal:<br />
        <code dir="ltr" translate="no">           'This is a prompt.'          </code><br />
        <br />
        String column name:<br />
        <code dir="ltr" translate="no">           my_string_column          </code></td>
        </tr>
        <tr class="even">
        <td><code dir="ltr" translate="no">           ObjectRefRuntime          </code><br />
        or<br />
        <code dir="ltr" translate="no">           ARRAY&lt;ObjectRefRuntime&gt;          </code></td>
        <td><p>An <code dir="ltr" translate="no">            ObjectRefRuntime           </code> value returned by the <a href="/bigquery/docs/reference/standard-sql/objectref_functions#objget_access_url"><code dir="ltr" translate="no">             OBJ.GET_ACCESS_URL            </code> function</a> . The <code dir="ltr" translate="no">            OBJ.GET_ACCESS_URL           </code> function takes an <a href="/bigquery/docs/analyze-multimodal-data#objectref_values"><code dir="ltr" translate="no">             ObjectRef            </code></a> value as input, which you can provide by either specifying the name of a column that contains <code dir="ltr" translate="no">            ObjectRef           </code> values, or by constructing an <code dir="ltr" translate="no">            ObjectRef           </code> value.</p>
        <p><code dir="ltr" translate="no">            ObjectRefRuntime           </code> values must have the <code dir="ltr" translate="no">            access_url.read_url           </code> and <code dir="ltr" translate="no">            details.gcs_metadata.content_type           </code> elements of the JSON value populated.</p>
        <p>Your input can contain at most one video object.</p></td>
        <td>Function call with <code dir="ltr" translate="no">           ObjectRef          </code> column:<br />
        <code dir="ltr" translate="no">           OBJ.GET_ACCESS_URL(my_objectref_column, 'r')          </code><br />
        <br />
        Function call with constructed <code dir="ltr" translate="no">           ObjectRef          </code> value:<br />
        <code dir="ltr" translate="no">           OBJ.GET_ACCESS_URL(OBJ.MAKE_REF('gs://image.jpg', 'myconnection'), 'r')          </code></td>
        </tr>
        </tbody>
        </table>
        The function combines `  STRUCT  ` fields similarly to a [`  CONCAT  `](/bigquery/docs/reference/standard-sql/string_functions#concat) operation and concatenates the fields in their specified order. The same is true for the elements of any arrays used within the struct. The following table shows some examples of `  STRUCT  ` prompt values and how they are interpreted:
        <table>
        <thead>
        <tr class="header">
        <th>Struct field types</th>
        <th>Struct value</th>
        <th>Semantic equivalent</th>
        </tr>
        </thead>
        <tbody>
        <tr class="odd">
        <td><code dir="ltr" translate="no">           STRUCT&lt;STRING, STRING, STRING&gt;          </code></td>
        <td><code dir="ltr" translate="no">           ('Describe the city of ', my_city_column, ' in 15 words')          </code></td>
        <td>'Describe the city of my_city_column_value in 15 words'</td>
        </tr>
        <tr class="even">
        <td><code dir="ltr" translate="no">           STRUCT&lt;STRING, ObjectRefRuntime&gt;          </code></td>
        <td><code dir="ltr" translate="no">           ('Describe                   the following city', OBJ.GET_ACCESS_URL(image_objectref_column, 'r'))          </code></td>
        <td>'Describe the following city image '</td>
        </tr>
        </tbody>
        </table>

<!-- end list -->

  - `  ENDPOINT  ` : a `  STRING  ` value that specifies the Vertex AI endpoint to use for the model. You can specify any [generally available](/vertex-ai/generative-ai/docs/models#generally_available_models) or [preview](/vertex-ai/generative-ai/docs/models#preview_models) Gemini model. If you specify the model name, BigQuery ML automatically identifies and uses the full endpoint of the model. If you don't specify an `  ENDPOINT  ` value, BigQuery ML selects a recent stable version of Gemini to use. The default endpoint is `  gemini-2.5-flash  ` .
    
    **Note:** Using Gemini 2.5 models incurs charges for the [thinking process](/vertex-ai/generative-ai/docs/thinking) . You can set a budget for the thinking process for Gemini 2.5 Flash and Gemini 2.5 Flash-Lite models by using the `  MODEL_PARAMS  ` argument to set the `  thinking_budget  ` parameter. For an example, see [Set the thinking budget for a Gemini 2.5 Flash model](#thinking-budget) . You can't set a budget for Gemini 2.5 Pro models.

  - `  MODEL_PARAMS  ` : a `  JSON  ` literal that provides additional parameters to the model. The `  MODEL_PARAMS  ` value must conform to the [`  generateContent  ` request body format](/vertex-ai/generative-ai/docs/reference/rest/v1/projects.locations.publishers.models/generateContent#request-body) . You can provide a value for any field in the request body except for the `  contents  ` field; the `  contents  ` field is populated with the `  PROMPT  ` argument value.

  - `  CONNECTION  ` : a `  STRING  ` value specifying the connection to use to communicate with the model, in the format `  [ PROJECT_ID ]. LOCATION . CONNECTION_ID  ` . For example, `  myproject.us.myconnection  ` .
    
    If you don't specify a connection, then the query uses your [end-user credentials](/bigquery/docs/permissions-for-ai-functions#run_generative_ai_queries_with_end-user_credentials) .
    
    For information about configuring permissions, see [Set permissions for BigQuery ML generative AI functions that call Vertex AI models](/bigquery/docs/permissions-for-ai-functions) .

  - `  REQUEST_TYPE  ` : a `  STRING  ` value that specifies the type of inference request to send to the Gemini model. The request type determines what quota the request uses. Valid values are as follows:
    
      - `  SHARED  ` : The function only uses [dynamic shared quota (DSQ)](/vertex-ai/generative-ai/docs/dynamic-shared-quota) .
    
      - `  DEDICATED  ` : The function only uses [Provisioned Throughput](/vertex-ai/generative-ai/docs/provisioned-throughput/overview) quota. The function returns an invalid query error if Provisioned Throughput quota isn't available. For more information, see [Use Vertex AI Provisioned Throughput](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-generate#provisioned-throughput) .
    
      - `  UNSPECIFIED  ` : The function uses quota as follows:
        
          - If you haven't purchased Provisioned Throughput quota, the function uses DSQ quota.
          - If you have purchased Provisioned Throughput quota, the function uses the Provisioned Throughput quota first. If requests exceed the Provisioned Throughput quota, the overflow traffic uses DSQ quota.
    
    The default value is `  UNSPECIFIED  ` .

## Output

`  AI.GENERATE_BOOL  ` returns a `  STRUCT  ` value for each row in the table. The struct contains the following fields:

  - `  result  ` : a `  BOOL  ` value containing the model's response to the prompt. The result is `  NULL  ` if the request fails or is filtered by [responsible AI](/vertex-ai/generative-ai/docs/learn/responsible-ai) .
  - `  full_response  ` : a JSON value containing the [response](/vertex-ai/generative-ai/docs/reference/rest/v1/GenerateContentResponse) from the [`  projects.locations.endpoints.generateContent  `](/vertex-ai/generative-ai/docs/reference/rest/v1/projects.locations.endpoints/generateContent) call to the model. The generated text is in the `  text  ` element.
  - `  status  ` : a `  STRING  ` value that contains the API response status for the corresponding row. This value is empty if the operation was successful.

## Examples

The following examples assume that you have granted the [Vertex AI User role](/vertex-ai/docs/general/access-control#aiplatform.user) to your personal account. For more information, see [Run generative AI queries with end-user credentials](/bigquery/docs/permissions-for-ai-functions#run_generative_ai_queries_with_end-user_credentials) .

### Use string input

To determine whether each city is located in the US, call the `  AI.GENERATE_BOOL  ` function and select the `  result  ` field in the output by running the following query:

``` text
SELECT
  city,
  AI.GENERATE_BOOL(('Is ', city, ' a US city?')).result
FROM UNNEST(["Seattle", "Beijing", "Paris", "London"]) city;
```

The result is similar to the following:

``` console
+---------+--------+
| city    | result |
+---------+--------+
| Seattle | true   |
| Beijing | false  |
| Paris   | false  |
| London  | false  |
+---------+--------+
```

### Filter rows using AI.GENERATE\_BOOL

You can use the `  AI.GENERATE_BOOL  ` function in a `  WHERE  ` clause to filter rows based on a condition described in natural language. The following example uses `  AI.GENERATE_BOOL  ` to filter news articles, and then uses the [`  AI.GENERATE  ` function](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-generate) to summarize the filtered articles:

``` text
SELECT
  title,
  AI.GENERATE((body, "Summarize the article in a single sentence.")).result
FROM `bigquery-public-data.bbc_news.fulltext`
WHERE
  AI.GENERATE_BOOL(
    (body, "Is this news article focused on US technology? ")).result
  AND category = "tech"
LIMIT 3;
```

The result is similar to the following:

``` console
+-----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
|               title               |                                                                          result                                                                          |
+-----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
| Commodore finds new lease of life | Legendary Commodore brand sold to Yeahronimo Media Ventures for Â£17m, with plans for new computers and a global entertainment concept.                   |
| Sony PSP handheld console hits US | Sony's PSP launches in US for $250, a portable entertainment device. It competes with Nintendo DS, offering games, music, video.                         |
| Gates opens biggest gadget fair   | Gates at CES: seamless device interoperability for managing multimedia content, online gaming, and strong electronics growth expected. No next-gen Xbox. |
+-----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
```

### Process images in a Cloud Storage bucket

The following query creates an external table from images of pet products stored in a publicly available Cloud Storage bucket:

``` text
CREATE SCHEMA IF NOT EXISTS bqml_tutorial;

CREATE OR REPLACE EXTERNAL TABLE bqml_tutorial.product_images
  WITH CONNECTION DEFAULT OPTIONS (
    object_metadata = 'SIMPLE',
    uris = ['gs://cloud-samples-data/bigquery/tutorials/cymbal-pets/images/*.png']);
```

To determine which animals are mammals, call the `  AI.GENERATE_BOOL  ` function and select the `  result  ` field in the output by running the following query:

``` text
SELECT
  uri,
  STRING(OBJ.GET_ACCESS_URL(ref,'r').access_urls.read_url) AS signed_url,
  AI.GENERATE_BOOL(("Is this cat food?", OBJ.GET_ACCESS_URL(ref, 'r'))).result
FROM bqml_tutorial.product_images
WHERE uri LIKE '%cat%';
```

The result is similar to the following:

### Set the thinking budget for a Gemini 2.5 Flash model

The following query shows how to set the `  model_params  ` argument to set the model's thinking budget to `  0  ` for the request:

``` text
SELECT
  city,
  AI.GENERATE_BOOL(('Is ', city, ' a US city?'),
    endpoint => 'gemini-2.5-flash',
    model_params => JSON '{"generation_config":{"thinking_config": {"thinking_budget": 0}}}')
FROM mydataset.cities;
```

## Best Practices

This function passes your input to a Gemini model and incurs charges in Vertex AI each time it's called. For information about how to view these charges, see [Track costs](/bigquery/docs/generative-ai-overview#track_costs) . To minimize Vertex AI charges when you use `  AI.GENERATE_BOOL  ` on a subset of data using the `  LIMIT  ` clause, materialize the selected data to a table first. For example, the first of the following examples is preferable to the second one:

``` text
CREATE TABLE mydataset.cities
AS (
  SELECT city_name from mydataset.customers LIMIT 10.
);

SELECT
  city,
  AI.GENERATE_BOOL(
    ('Is ', city, ' a US city?')).result
FROM mydataset.cities;
```

``` text
SELECT
  city,
  AI.GENERATE_BOOL(
    ('Is ', city, ' a US city?')).result
FROM (SELECT city_name from mydataset.customers LIMIT 10);
```

Writing the query results to a table beforehand helps you to ensure that you are sending as few rows as possible to the model.

## Use Vertex AI Provisioned Throughput

You can use [Vertex AI Provisioned Throughput](/vertex-ai/generative-ai/docs/provisioned-throughput/overview) with the `  AI.GENERATE_BOOL  ` function to provide consistent high throughput for requests. The remote model that you reference in the `  AI.GENERATE_BOOL  ` function must use a [supported Gemini model](/vertex-ai/generative-ai/docs/provisioned-throughput/supported-models) in order for you to use Provisioned Throughput.

To use Provisioned Throughput, [calculate your Provisioned Throughput requirements](/vertex-ai/generative-ai/docs/provisioned-throughput/measure-provisioned-throughput) and then [purchase Provisioned Throughput](/vertex-ai/generative-ai/docs/provisioned-throughput/purchase-provisioned-throughput) quota before running the `  AI.GENERATE_BOOL  ` function. When you purchase Provisioned Throughput, do the following:

  - For **Model** , select the same Gemini model as the one used by the remote model that you reference in the `  AI.GENERATE_BOOL  ` function.

  - For **Region** , select the same region as the dataset that contains the remote model that you reference in the `  AI.GENERATE_BOOL  ` function, with the following exceptions:
    
      - If the dataset is in the `  US  ` multi-region, select the `  us-central1  ` region.
      - If the dataset is in the `  EU  ` multi-region, select the `  europe-west4  ` region.

After you submit the order, wait for the order to be approved and appear on the [**Orders**](https://console.cloud.google.com/vertex-ai/provisioned-throughput) page.

After you have purchased Provisioned Throughput quota, use the `  REQUEST_TYPE  ` argument to determine how the `  AI.GENERATE_BOOL  ` function uses the quota.

## Locations

You can run `  AI.GENERATE_BOOL  ` in all of the [regions](/vertex-ai/generative-ai/docs/learn/locations#google_model_endpoint_locations) that support Gemini models, and also in the `  US  ` and `  EU  ` multi-regions.

## Quotas

See [Vertex AI and Cloud AI service functions quotas and limits](/bigquery/quotas#cloud_ai_service_functions) .

## What's next

  - For more information about using Vertex AI models to generate text and embeddings, see [Generative AI overview](/bigquery/docs/generative-ai-overview) .
  - For more information about using Cloud AI APIs to perform AI tasks, see [AI application overview](/bigquery/docs/ai-application-overview) .
  - For more information about supported SQL statements and functions for generative AI models, see [End-to-end user journeys for generative AI models](/bigquery/docs/e2e-journey-genai) .
