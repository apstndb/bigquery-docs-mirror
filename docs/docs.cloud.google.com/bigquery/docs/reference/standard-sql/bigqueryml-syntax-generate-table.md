# The AI.GENERATE\_TABLE function

This document describes the `  AI.GENERATE_TABLE  ` function, which lets you perform generative natural language tasks by using any combination of text and unstructured data from BigQuery [standard tables](/bigquery/docs/tables-intro#standard-tables) , and also specify a schema to format the response from the model.

The function works by sending requests to a BigQuery ML remote model that represents a Vertex AI Gemini model, and then returning that model's response. The function supports remote models over any of the [generally available](/vertex-ai/generative-ai/docs/models#generally_available_models) or [preview](/vertex-ai/generative-ai/docs/models#preview_models) Gemini models.

Several of the `  AI.GENERATE_TABLE  ` function's arguments provide the parameters that shape the Vertex AI model's response.

You can use the `  AI.GENERATE_TABLE  ` function to perform tasks such as classification, sentiment analysis, image captioning, and transcription.

Prompt design can strongly affect the responses returned by the Vertex AI model. For more information, see [Introduction to prompting](/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design) .

## Input

Using the `  AI.GENERATE_TABLE  ` function, you can use the following types of input:

  - Text data from standard tables.
  - [`  ObjectRefRuntime  `](/bigquery/docs/reference/standard-sql/objectref_functions#objectrefruntime) values that are generated by the [`  OBJ.GET_ACCESS_URL  ` function](/bigquery/docs/reference/standard-sql/objectref_functions#objget_access_url) . You can use [`  ObjectRef  `](/bigquery/docs/reference/standard-sql/objectref_functions#objectref) values from standard tables as input to the `  OBJ.GET_ACCESS_URL  ` function. ( [Preview](https://cloud.google.com/products#product-launch-stages) )

When you analyze unstructured data, that data must meet the following requirements:

  - Content must be in one of the supported formats that are described in the Gemini API model [`  mimeType  ` parameter](/vertex-ai/generative-ai/docs/model-reference/gemini#parameters) .
  - If you are analyzing a video, the maximum supported length is two minutes. If the video is longer than two minutes, `  AI.GENERATE_TABLE  ` only returns results for the first two minutes.

## Syntax

``` googlesql
AI.GENERATE_TABLE(
MODEL `PROJECT_ID.DATASET.MODEL`,
{ TABLE `PROJECT_ID.DATASET.TABLE` | (QUERY_STATEMENT) },
STRUCT(
  OUTPUT_SCHEMA AS output_schema
  [, MAX_OUTPUT_TOKENS AS max_output_tokens]
  [, TOP_P AS top_p]
  [, TEMPERATURE AS temperature]
  [, STOP_SEQUENCES AS stop_sequences]
  [, SAFETY_SETTINGS AS safety_settings]
  [, REQUEST_TYPE AS request_type])
)
```

### Arguments

`  AI.GENERATE_TABLE  ` takes the following arguments:

  - `  PROJECT_ID  ` : the project that contains the resource.

  - `  DATASET  ` : the dataset that contains the resource.

  - `  MODEL  ` : the name of the remote model. For more information, see [The `  CREATE MODEL  ` statement for remote models over LLMs](/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model) .
    
    **Note:** Using a remote model based on a Gemini 2.5 model incurs charges for the [thinking process](/vertex-ai/generative-ai/docs/thinking) .

  - `  TABLE  ` : the name of the BigQuery table that contains the prompt data. The text in the column that's named `  prompt  ` is sent to the model. If your table does not have a `  prompt  ` column, use the `  QUERY_STATEMENT  ` argument instead and provide a `  SELECT  ` statement that includes an alias for an existing table column. An error occurs if no `  prompt  ` column is available.

  - `  QUERY_STATEMENT  ` : the GoogleSQL query that generates the prompt data. The query must produce a column named `  prompt  ` . Within the query, you can provide the prompt value in the following ways:
    
      - Specify a `  STRING  ` value. For example, `  ('Write a poem about birds')  ` .
    
      - Specify a `  STRUCT  ` value that contains one or more fields. You can use the following types of fields within the struct value:
        
        <table>
        <colgroup>
        <col style="width: 33%" />
        <col style="width: 33%" />
        <col style="width: 33%" />
        </colgroup>
        <thead>
        <tr class="header">
        <th>Field type</th>
        <th>Description</th>
        <th>Examples</th>
        </tr>
        </thead>
        <tbody>
        <tr class="odd">
        <td><code dir="ltr" translate="no">           STRING          </code><br />
        or<br />
        <code dir="ltr" translate="no">           ARRAY&lt;STRING&gt;          </code></td>
        <td>A string literal, array of string literals, or the name of a <code dir="ltr" translate="no">           STRING          </code> column.</td>
        <td>String literal:<br />
        <code dir="ltr" translate="no">           'Is Seattle a US city?'          </code><br />
        <br />
        String column name:<br />
        <code dir="ltr" translate="no">           my_string_column          </code></td>
        </tr>
        <tr class="even">
        <td><code dir="ltr" translate="no">           ObjectRefRuntime          </code><br />
        or<br />
        <code dir="ltr" translate="no">           ARRAY&lt;ObjectRefRuntime&gt;          </code></td>
        <td><p>An <code dir="ltr" translate="no">            ObjectRefRuntime           </code> value returned by the <a href="/bigquery/docs/reference/standard-sql/objectref_functions#objget_access_url"><code dir="ltr" translate="no">             OBJ.GET_ACCESS_URL            </code> function</a> . The <code dir="ltr" translate="no">            OBJ.GET_ACCESS_URL           </code> function takes an <a href="/bigquery/docs/analyze-multimodal-data#objectref_values"><code dir="ltr" translate="no">             ObjectRef            </code></a> value as input, which you can provide by either specifying the name of a column that contains <code dir="ltr" translate="no">            ObjectRef           </code> values, or by constructing an <code dir="ltr" translate="no">            ObjectRef           </code> value.</p>
        <p><code dir="ltr" translate="no">            ObjectRefRuntime           </code> values must have the <code dir="ltr" translate="no">            access_url.read_url           </code> and <code dir="ltr" translate="no">            details.gcs_metadata.content_type           </code> elements of the JSON value populated.</p></td>
        <td>Function call with <code dir="ltr" translate="no">           ObjectRef          </code> column:<br />
        <code dir="ltr" translate="no">           OBJ.GET_ACCESS_URL(my_objectref_column, 'r')          </code><br />
        <br />
        Function call with constructed <code dir="ltr" translate="no">           ObjectRef          </code> value:<br />
        <code dir="ltr" translate="no">           OBJ.GET_ACCESS_URL(OBJ.MAKE_REF('gs://image.jpg', 'myconnection'), 'r')          </code></td>
        </tr>
        </tbody>
        </table>
        
        The function combines `  STRUCT  ` fields similarly to a [`  CONCAT  `](/bigquery/docs/reference/standard-sql/string_functions#concat) operation and concatenates the fields in their specified order. The same is true for the elements of any arrays used within the struct. The following table shows some examples of `  STRUCT  ` prompt values and how they are interpreted:
        
        <table>
        <thead>
        <tr class="header">
        <th>Struct field types</th>
        <th>Struct value</th>
        <th>Semantic equivalent</th>
        </tr>
        </thead>
        <tbody>
        <tr class="odd">
        <td><code dir="ltr" translate="no">           STRUCT&lt;STRING, STRING, STRING&gt;          </code></td>
        <td><code dir="ltr" translate="no">           ('Describe the city ', my_city_column, ' in 15 words')          </code></td>
        <td>'Describe the city my_city_column_value in 15 words'</td>
        </tr>
        <tr class="even">
        <td><code dir="ltr" translate="no">           STRUCT&lt;STRING, ObjectRefRuntime&gt;          </code></td>
        <td><code dir="ltr" translate="no">           ('Describe this city', OBJ.GET_ACCESS_URL(image_objectref_column, 'r'))          </code></td>
        <td>'Describe this city' image</td>
        </tr>
        </tbody>
        </table>
    
    **Note:** To minimize Vertex AI charges, write query results to a table and then reference that table in the `  AI.GENERATE_TABLE  ` function. This can help you ensure that you are sending as few rows as possible to the model.

  - `  OUTPUT_SCHEMA  ` : a `  STRING  ` value that specifies the schema of the output as a comma-separated list of fields. Each field consists of a name, a data type, and an optional `  OPTIONS  ` clause in which you can specify a description of the field. The following example shows how to specify an output schema that contains two string fields, `  name  ` and `  state  ` , with a description for the `  state  ` field:
    
    ``` text
    '''
    name STRING,
    state STRING OPTIONS(description = 'The 2-letter abbreviation of the state name')
    ''' AS output_schema
    ```
    
    Supported data types include `  STRING  ` , `  INT64  ` , `  FLOAT64  ` , `  BOOL  ` , `  ARRAY  ` , and `  STRUCT  ` . For a `  STRUCT  ` data type, you can specify the `  OPTIONS  ` clause on any of its subfields:
    
    ``` text
    '''
    location STRUCT<city STRING,
    state STRING OPTIONS(description = 'The 2-letter abbreviation of the state name')>
    ''' AS output_schema
    ```

#### Show additional optional parameters

  - `  MAX_OUTPUT_TOKENS  ` : an `  INT64  ` value that sets the maximum number of tokens that can be generated in the response. A token might be smaller than a word and is approximately four characters. One hundred tokens correspond to approximately 60-80 words.This value must be in the range `  [1,8192]  ` . Specify a lower value for shorter responses and a higher value for longer responses. If you don't specify a value, the model determines an appropriate value.

  - `  TOP_P  ` : a `  FLOAT64  ` value in the range `  [0.0,1.0]  ` that changes how the model selects tokens for output. Specify a lower value for less random responses and a higher value for more random responses. If you don't specify a value, the model determines an appropriate value.
    
    Tokens are selected from the most to least probable until the sum of their probabilities equals the `  TOP_P  ` value. For example, if tokens A, B, and C have a probability of `  0.3  ` , `  0.2  ` , and `  0.1  ` , and the `  TOP_P  ` value is `  0.5  ` , then the model selects either A or B as the next token by using the `  TEMPERATURE  ` value and doesn't consider C.

  - `  TEMPERATURE  ` : a `  FLOAT64  ` value in the range `  [0.0,2.0]  ` that controls the degree of randomness in token selection. Lower `  TEMPERATURE  ` values are good for prompts that require a more deterministic and less open-ended or creative response, while higher `  TEMPERATURE  ` values can lead to more diverse or creative results. A `  TEMPERATURE  ` value of `  0  ` is deterministic, meaning that the highest probability response is always selected. If you don't specify a value, the model determines an appropriate value.

  - `  STOP_SEQUENCES  ` : an `  ARRAY<STRING>  ` value that removes the specified strings if they are included in responses from the model. Strings are matched exactly, including capitalization. The default is an empty array.

  - `  SAFETY_SETTINGS  ` : an `  ARRAY<STRUCT<STRING AS category, STRING AS threshold>>  ` value that configures content safety thresholds to filter responses. The first element in the struct specifies a harm category, and the second element in the struct specifies a corresponding blocking threshold. The model filters out content that violate these settings. You can only specify each category once. For example, you can't specify both `  STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold)  ` and `  STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)  ` . If there is no safety setting for a given category, the `  BLOCK_MEDIUM_AND_ABOVE  ` safety setting is used.
    
    Supported categories are as follows:
    
      - `  HARM_CATEGORY_HATE_SPEECH  `
      - `  HARM_CATEGORY_DANGEROUS_CONTENT  `
      - `  HARM_CATEGORY_HARASSMENT  `
      - `  HARM_CATEGORY_SEXUALLY_EXPLICIT  `
    
    Supported thresholds are as follows:
    
      - `  BLOCK_NONE  ` ( [Restricted](/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters#how_to_configure_content_filters) )
      - `  BLOCK_LOW_AND_ABOVE  `
      - `  BLOCK_MEDIUM_AND_ABOVE  ` (Default)
      - `  BLOCK_ONLY_HIGH  `
      - `  HARM_BLOCK_THRESHOLD_UNSPECIFIED  `
    
    For more information, see [Harm categories](/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters#harm_categories) and [How to configure content filters](/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters#how-to-configure-content-filters) .

  - `  REQUEST_TYPE  ` : a `  STRING  ` value that specifies the type of inference request to send to the Gemini model. The request type determines what quota the request uses. Valid values are as follows:
    
      - `  DEDICATED  ` : The `  AI.GENERATE_TABLE  ` function only uses Provisioned Throughput quota. The `  AI.GENERATE_TABLE  ` function returns the error `  Provisioned throughput is not purchased or is not active  ` if Provisioned Throughput quota isn't available.
      - `  SHARED  ` : The `  AI.GENERATE_TABLE  ` function only uses [dynamic shared quota (DSQ)](/vertex-ai/generative-ai/docs/dynamic-shared-quota) , even if you have purchased Provisioned Throughput quota.
      - `  UNSPECIFIED  ` : The `  AI.GENERATE_TABLE  ` function uses quota as follows:
          - If you haven't purchased Provisioned Throughput quota, the `  AI.GENERATE_TABLE  ` function uses DSQ quota.
          - If you have purchased Provisioned Throughput quota, the `  AI.GENERATE_TABLE  ` function uses the Provisioned Throughput quota first. If requests exceed the Provisioned Throughput quota, the overflow traffic uses DSQ quota.
    
    The default value is `  UNSPECIFIED  ` .

## Examples

The following examples demonstrate how to use `  AI.GENERATE_TABLE  ` .

### Format text input

The following example shows a request that provides a SQL schema to format the model's response. It specifies a description in the `  OPTIONS  ` clause for the `  weight  ` field to indicate that the result should be given in kilograms.

``` text
SELECT
  address,
  age,
  is_married,
  name,
  phone_number,
  weight
FROM
AI.GENERATE_TABLE( MODEL `mydataset.gemini_model`,
  (
      SELECT
        '''John Smith is a 20-year old single man living at 1234 NW 45th St, Kirkland WA, 98033.
        He has two phone numbers 123-123-1234, and 234-234-2345. He is 200.5 pounds.''' AS prompt
  ),
  STRUCT('''address STRING, age INT64, is_married BOOL, name STRING, phone_number ARRAY<STRING>,
            weight FLOAT64 OPTIONS(description = "in kilograms")''' AS output_schema,
          8192 AS max_output_tokens));
```

The results look similar to the following:

``` console
+-------------------------------------+-----+------------+------------+---------------+-----------+
| address                             | age | is_married | name       | phone_number  | weight    |
+-------------------------------------+-----+------------+------------+---------------+-----------+
| 1234 NW 45th St, Kirkland WA, 98033 | 20  | No         | John Smith | 123-123-1234  | 90.947236 |
|                                     |     |            |            | 234-234-2345  |           |
|                                     |     |            |            |               |           |
+-------------------------------------+-----+------------+------------+---------------+-----------+
```

### Create a column based on image data

The following example shows how to to create and populate an `  image_description  ` column by analyzing a product image that is stored as an `  ObjectRef  ` value in a standard table:

``` text
CREATE OR REPLACE TABLE
  `mydataset.products`
AS
  SELECT
  product_id,
  product_name,
  image,
  image_description
FROM
AI.GENERATE_TABLE( MODEL `mydataset.gemini`,
  (
  SELECT
    ('Can you describe the following image?',
      OBJ.GET_ACCESS_URL(image, 'r')) AS prompt,
    *
  FROM
   `mydataset.products` ),
  STRUCT ( "image_description STRING" AS output_schema ));
```

## Details

The model and input table must be in the same region.

## Output

`  AI.GENERATE_TABLE  ` returns the following columns:

  - All columns in the input table.

  - All columns specified in the `  output_response  ` argument.

  - `  full_response  ` : this is the [JSON response](/vertex-ai/generative-ai/docs/reference/rest/v1/GenerateContentResponse) from the [`  projects.locations.endpoints.generateContent  `](/vertex-ai/generative-ai/docs/reference/rest/v1/projects.locations.endpoints/generateContent) call to the model. The generated data is in the `  text  ` element.

  - `  status  ` : a `  STRING  ` value that contains the API response status for the corresponding row. This value is empty if the operation was successful.

## Locations

`  AI.GENERATE_TABLE  ` must run in the same [region or multi-region](/bigquery/docs/locations) as the remote model that the function references.

You can create remote models over Gemini models in the [supported regions](/vertex-ai/generative-ai/docs/learn/locations#available-regions) for the given Gemini model, and also in the `  US  ` and `  EU  ` multi-regions.

## Quotas

See [Vertex AI and Cloud AI service functions quotas and limits](/bigquery/quotas#cloud_ai_service_functions) .

## Known issues

This section contains information about known issues.

### Resource exhausted errors

Sometimes after a query job that uses this function finishes successfully, some returned rows contain the following error message:

``` text
A retryable error occurred: RESOURCE EXHAUSTED error from <remote endpoint>
```

This issue occurs because BigQuery query jobs finish successfully even if the function fails for some of the rows. The function fails when the volume of API calls to the remote endpoint exceeds the quota limits for that service. This issue occurs most often when you are running multiple parallel batch queries. BigQuery retries these calls, but if the retries fail, the `  resource exhausted  ` error message is returned.

To iterate through inference calls until all rows are successfully processed, you can use the [BigQuery remote inference SQL scripts](https://github.com/GoogleCloudPlatform/bigquery-ml-utils/tree/master/sql_scripts/remote_inference) or the [BigQuery remote inference pipeline Dataform package](https://github.com/dataform-co/dataform-bqml) .

## What's next

  - Get step-by-step instructions on how to [generate structured data](/bigquery/docs/generate-table) using your own data.
  - For more information about using Vertex AI models to generate text and embeddings, see [Generative AI overview](/bigquery/docs/generative-ai-overview) .
  - For more information about using Cloud AI APIs to perform AI tasks, see [AI application overview](/bigquery/docs/ai-application-overview) .
  - For more information about supported SQL statements and functions for generative AI models, see [End-to-end user journeys for generative AI models](/bigquery/docs/e2e-journey-genai) .
